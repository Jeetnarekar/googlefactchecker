{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8970, 3)\n"
     ]
    }
   ],
   "source": [
    "# run in Colab / local python\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "base = \"https://www.politifact.com\"\n",
    "# example: iterate pages ‚Äî adjust to actual Politifact pages you need\n",
    "for page in range(1, 300):\n",
    "    url = f\"https://www.politifact.com/factchecks/list/?page={page}\"\n",
    "    r = requests.get(url, headers={\"User-Agent\":\"Mozilla/5.0\"})\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    cards = soup.select(\".o-listicle__item\")  # selector may change; inspect site\n",
    "    for c in cards:\n",
    "        stmt = c.select_one(\".m-statement__quote\")\n",
    "        rating = c.select_one(\".m-statement__meter .c-image\")\n",
    "        source = c.select_one(\".m-statement__meta\")\n",
    "        if stmt:\n",
    "            statement = stmt.get_text(strip=True)\n",
    "            rating_text = rating['alt'] if rating and rating.has_attr('alt') else None\n",
    "            source_text = source.get_text(\" \", strip=True) if source else None\n",
    "            rows.append({\"statement\":statement,\"rating\":rating_text,\"source\":source_text})\n",
    "    time.sleep(1.5)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(\"politifact_scraped.csv\", index=False)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) Load CSV, basic cleaning, create binary labels\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"politifact_dataset.csv\")  # or the scraped CSV\n",
    "# drop unwanted column(s)\n",
    "df = df.drop(columns=[c for c in df.columns if c.lower().startswith(\"unnamed\")], errors='ignore')\n",
    "\n",
    "# normalize rating -> binary (example mapping)\n",
    "true_labels = [\"true\", \"mostly-true\", \"mostly true\", \"true-ish\", \"mostly true\"]  # expand as needed\n",
    "false_labels = [\"false\", \"pants-fire\", \"mostly-false\", \"mostly false\"]\n",
    "\n",
    "def map_binary(r):\n",
    "    if pd.isna(r): return None\n",
    "    t = str(r).lower()\n",
    "    if any(x in t for x in true_labels): return 1\n",
    "    if any(x in t for x in false_labels): return 0\n",
    "    return None\n",
    "\n",
    "df['BinaryNumTarget'] = df['target'].apply(map_binary)  # or df['rating']\n",
    "df = df.dropna(subset=['statement','BinaryNumTarget'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>statement</th>\n",
       "      <th>source</th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "      <th>BinaryTarget</th>\n",
       "      <th>BinaryNumTarget</th>\n",
       "      <th>Fake</th>\n",
       "      <th>Real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marta Campabadal</td>\n",
       "      <td>‚ÄúNetflix estren√≥ una pel√≠cula del Titan el 23 ...</td>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>June 29, 2023</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Louis Jacobson</td>\n",
       "      <td>Says that under his presidency, the unemployme...</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>June 29, 2023</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>REAL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jeff Cercone</td>\n",
       "      <td>\"ONU ordena despenalizar a los\" ped√≥filos.</td>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>June 29, 2023</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sara Swann</td>\n",
       "      <td>NASA warns of ‚Äúinternet apocalypse,‚Äù which ‚Äúme...</td>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>June 29, 2023</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jeff Cercone</td>\n",
       "      <td>Video suggests COVID-19 vaccines are responsib...</td>\n",
       "      <td>Instagram posts</td>\n",
       "      <td>June 29, 2023</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author                                          statement  \\\n",
       "0  Marta Campabadal  ‚ÄúNetflix estren√≥ una pel√≠cula del Titan el 23 ...   \n",
       "1    Louis Jacobson  Says that under his presidency, the unemployme...   \n",
       "2      Jeff Cercone         \"ONU ordena despenalizar a los\" ped√≥filos.   \n",
       "3        Sara Swann  NASA warns of ‚Äúinternet apocalypse,‚Äù which ‚Äúme...   \n",
       "4      Jeff Cercone  Video suggests COVID-19 vaccines are responsib...   \n",
       "\n",
       "            source           date       target BinaryTarget  BinaryNumTarget  \\\n",
       "0   Facebook posts  June 29, 2023        FALSE         FAKE              0.0   \n",
       "1        Joe Biden  June 29, 2023  mostly-true         REAL              1.0   \n",
       "2   Facebook posts  June 29, 2023        FALSE         FAKE              0.0   \n",
       "3   Facebook posts  June 29, 2023        FALSE         FAKE              0.0   \n",
       "4  Instagram posts  June 29, 2023        FALSE         FAKE              0.0   \n",
       "\n",
       "   Fake  Real  \n",
       "0  FAKE   NaN  \n",
       "1   NaN  REAL  \n",
       "2  FAKE   NaN  \n",
       "3  FAKE   NaN  \n",
       "4  FAKE   NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Feature extraction (TF-IDF) ‚Äî Spark MLlib (prepare DataFrame)\n",
    "\n",
    "Use PySpark in Colab (install Java + pyspark) or run on your cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PySpark setup (in Colab, you must install pyspark & Java)\n",
    "# !apt-get install -y openjdk-11-jdk\n",
    "# !pip install pyspark\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"politifact\").getOrCreate()\n",
    "\n",
    "# load csv into spark\n",
    "sdf = spark.read.csv(\"politifact_dataset.csv\", header=True, inferSchema=True)\n",
    "sdf = sdf.dropna(subset=[\"statement\",\"BinaryNumTarget\"]).withColumnRenamed(\"BinaryNumTarget\",\"label\")\n",
    "\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer\n",
    "\n",
    "regexTok = RegexTokenizer(inputCol=\"statement\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "rem = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"rawFeatures\", vocabSize=20000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[regexTok, rem, cv, idf])\n",
    "model = pipeline.fit(sdf)\n",
    "sdf_feat = model.transform(sdf) \\\n",
    "    .withColumn(\"label\", col(\"label\").cast(\"integer\")) \\\n",
    "    .select(\"statement\", \"label\", \"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(statement='‚ÄúNetflix estren√≥ una pel√≠cula del Titan el 23 de junio‚Äù.', label=0, features=SparseVector(4930, {9: 3.5012, 51: 4.211, 180: 4.9861, 233: 4.9861, 235: 4.9861, 1007: 6.1347, 1893: 6.5025, 2325: 7.0902, 2622: 7.0902, 3135: 7.0902, 3404: 7.0902}))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryNumTarget\n",
      "0    5168\n",
      "1     832\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"BinaryNumTarget\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Logistic Regression using Spark MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: {0: 4134, 1: 666}\n",
      "After SMOTE: {0: 4134, 1: 4134}\n",
      "Accuracy: 0.9816666666666667\n",
      "ROC-AUC: 0.9952051921418751\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      1034\n",
      "           1       0.89      0.99      0.94       166\n",
      "\n",
      "    accuracy                           0.98      1200\n",
      "   macro avg       0.94      0.98      0.96      1200\n",
      "weighted avg       0.98      0.98      0.98      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def spacy_preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    # Keep lemmatized tokens that are not stop words or punctuations\n",
    "    tokens = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Example usage\n",
    "df[\"statement\"] = df[\"statement\"].apply(spacy_preprocess)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"politifact_dataset.csv\")\n",
    "\n",
    "# Drop unwanted and null rows\n",
    "df = df.drop(columns=[c for c in df.columns if c.lower().startswith(\"unnamed\")], errors='ignore')\n",
    "df = df.dropna(subset=[\"statement\", \"BinaryNumTarget\"])\n",
    "\n",
    "# Convert labels to int (if needed)\n",
    "df[\"BinaryNumTarget\"] = df[\"BinaryNumTarget\"].astype(int)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X = df[\"statement\"]\n",
    "y = df[\"BinaryNumTarget\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=10000, stop_words=\"english\")\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tfidf, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_bal, y_train_bal = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Before SMOTE:\", y_train.value_counts().to_dict())\n",
    "print(\"After SMOTE:\", dict(zip(*np.unique(y_train_bal, return_counts=True))))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "lr = LogisticRegression(max_iter=200)\n",
    "lr.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "# Predict\n",
    "y_pred = lr.predict(X_test)\n",
    "y_prob = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Decision Tree on statement & rating (Spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9366666666666666\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "\n",
    "# SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "model = LinearSVC()\n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "\n",
    "model.fit(X_train_bal, y_train_bal)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Support Vector Machine (LinearSVC) in Spark MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Support Vector Machine Results\n",
      "Accuracy: 0.9975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1034\n",
      "           1       0.98      1.00      0.99       166\n",
      "\n",
      "    accuracy                           1.00      1200\n",
      "   macro avg       0.99      1.00      0.99      1200\n",
      "weighted avg       1.00      1.00      1.00      1200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jeet Kumar Narekar\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc = LinearSVC()\n",
    "svc.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "y_pred_svc = svc.predict(X_test)\n",
    "\n",
    "print(\"üîπ Support Vector Machine Results\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svc))\n",
    "print(classification_report(y_test, y_pred_svc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Naive Bayes (Spark MLlib)\n",
    "\n",
    "NaiveBayes expects non-negative features ‚Äî CountVectorizer raw counts are fine (so use rawFeatures instead of IDF features for NB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Naive Bayes Results\n",
      "Accuracy: 0.9366666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96      1034\n",
      "           1       0.69      0.99      0.81       166\n",
      "\n",
      "    accuracy                           0.94      1200\n",
      "   macro avg       0.84      0.96      0.89      1200\n",
      "weighted avg       0.96      0.94      0.94      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "print(\"üîπ Naive Bayes Results\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) KMeans clustering ‚Äî cluster true vs false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ K-Means Clustering Results\n",
      "BinaryNumTarget     0    1\n",
      "cluster                   \n",
      "0                 556   44\n",
      "1                4612  788\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Cluster using 2 clusters (true/false)\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "kmeans.fit(X_tfidf)\n",
    "\n",
    "# Get cluster labels\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# Compare clusters vs true labels\n",
    "df[\"cluster\"] = cluster_labels\n",
    "\n",
    "print(\"üîπ K-Means Clustering Results\")\n",
    "print(df.groupby([\"cluster\", \"BinaryNumTarget\"]).size().unstack(fill_value=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kmeans_model.joblib']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(vectorizer, \"tfidf_vectorizer.joblib\")\n",
    "joblib.dump(lr, \"logistic_regression_model.joblib\")\n",
    "joblib.dump(nb, \"naive_bayes_model.joblib\")\n",
    "joblib.dump(svc, \"svc_model.joblib\")\n",
    "joblib.dump(kmeans, \"kmeans_model.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Create DataFrame in Colab, convert to SQL table, and query\n",
    "\n",
    "Using sqlite3 or duckdb in Colab is easiest.\n",
    "\n",
    "sqlite3 example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('/content/politifact.db')\n",
    "df.to_sql('politifact', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Query\n",
    "q = \"SELECT target, COUNT(*) as cnt FROM politifact GROUP BY target ORDER BY cnt DESC;\"\n",
    "pd.read_sql(q, conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pip install duckdb\n",
    "import duckdb\n",
    "duckdb.sql(\"CREATE TABLE politifact AS SELECT * FROM read_csv_auto('polifact_full.csv')\")\n",
    "duckdb.sql(\"SELECT target, count(*) FROM politifact GROUP BY target\").df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
